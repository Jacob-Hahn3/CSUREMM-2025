{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66bdd433-0074-48b5-afb9-1fd3aaaf0b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "import warnings\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import geopandas as gpd\n",
    "\n",
    "# Scikit-learn preprocessing and imputation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Scikit-learn models\n",
    "from sklearn.linear_model import Ridge, Lasso, BayesianRidge, LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Scikit-learn model selection and evaluation\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    KFold,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    r2_score,\n",
    "    make_scorer\n",
    ")\n",
    "\n",
    "# Scikit-learn pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import (\n",
    "    het_breuschpagan,\n",
    "    acorr_breusch_godfrey\n",
    ")\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Scipy\n",
    "from scipy.stats import shapiro, anderson\n",
    "\n",
    "# SHAP for model interpretation\n",
    "import shap\n",
    "\n",
    "\n",
    "# Read from local shapefile\n",
    "gdf = gpd.read_file(\"cb_2020_us_county_20m/cb_2020_us_county_20m.shp\")\n",
    "# Create FIPS code and convert to GeoJSON format\n",
    "gdf['id'] = gdf['STATEFP'] + gdf['COUNTYFP']\n",
    "counties = json.loads(gdf[['id', 'geometry']].to_json())\n",
    "# Convert to GeoJSON dict for Plotly\n",
    "dcounties = json.loads(gdf.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09df9fb0-f17a-4c35-9e08-f85f4dc91956",
   "metadata": {},
   "source": [
    "# Functions\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d68ab0a2-49a4-45a1-b2aa-53d104f4c9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "def MC(dataset):\n",
    "    # === Load and clean data ===\n",
    "    df = pd.read_excel(dataset)\n",
    "    df = df[df['County'].notna()]\n",
    "    target_col = '% Vaccinated'\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df = df.dropna(subset=[target_col])\n",
    "    temp = df['FIPS'].astype(str).str.pad(5, 'left', '0')\n",
    "    df = df.drop(columns=['FIPS'], errors='ignore')\n",
    "    \n",
    "    X = df.drop(columns=[target_col]).select_dtypes(include=[np.number])\n",
    "    y = df[target_col]\n",
    "    X, y = X.align(y, join='inner', axis=0)\n",
    "\n",
    "    X = X.loc[:, X.isnull().mean() <= 0.20]\n",
    "    X = X.clip(-1e3, 1e3)\n",
    "    low_var_cols = X.var()[X.var() < 1e-8].index.tolist()\n",
    "    X = X.drop(columns=low_var_cols)\n",
    "\n",
    "    # === 90/10 holdout split ===\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    # === Hyperparameter space ===\n",
    "    param_dist = {\n",
    "        'n_estimators': [100, 200, 300],             # more trees, learn slowly\n",
    "        'max_depth': [2, 3, 4],                      # shallower trees\n",
    "        'learning_rate': [0.01, 0.03, 0.05],         # smaller steps\n",
    "        'subsample': [0.6, 0.8],                     # partial row sampling\n",
    "        'colsample_bytree': [0.6, 0.8],              # partial feature sampling\n",
    "        'gamma': [0.1, 0.3, 0.5],                    # avoid small splits\n",
    "        'reg_alpha': [0, 0.1, 0.5],                  # L1 penalty\n",
    "        'reg_lambda': [1, 2, 5],                     # L2 penalty\n",
    "    }\n",
    "\n",
    "\n",
    "    # === Hyperparameter search: outer loop ===\n",
    "    n_trials = 50\n",
    "    n_iterations = 5  # Monte Carlo splits per hyperparam set\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for t in range(n_trials):\n",
    "        params = {k: np.random.choice(v) for k, v in param_dist.items()}\n",
    "        print(f\"\\nðŸ” Trial {t + 1}/{n_trials} with params: {params}\")\n",
    "\n",
    "        rmses = []\n",
    "        r2s = []\n",
    "        mapes = []\n",
    "\n",
    "        # Monte Carlo iterations: inner loop\n",
    "        for i in range(n_iterations):\n",
    "            X_train, X_val, y_train, y_val = train_test_split(\n",
    "                X_train_full, y_train_full, test_size=0.2, random_state=np.random.randint(10000)\n",
    "            )\n",
    "            model = XGBRegressor(random_state=42, **params)\n",
    "            pipeline = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('model', model)\n",
    "            ])\n",
    "\n",
    "            try:\n",
    "                pipeline.fit(X_train, y_train)\n",
    "                y_pred = pipeline.predict(X_val)\n",
    "\n",
    "                rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "                r2 = r2_score(y_val, y_pred)\n",
    "                nonzero_mask = y_val != 0\n",
    "                mape = np.mean(\n",
    "                    np.abs((y_val[nonzero_mask] - y_pred[nonzero_mask]) / y_val[nonzero_mask])\n",
    "                ) * 100\n",
    "\n",
    "                rmses.append(rmse)\n",
    "                r2s.append(r2)\n",
    "                mapes.append(mape)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Iteration {i + 1} failed: {e}\")\n",
    "\n",
    "        # Average performance over Monte Carlo splits\n",
    "        avg_rmse = np.mean(rmses)\n",
    "        avg_r2 = np.mean(r2s)\n",
    "        avg_mape = np.mean(mapes)\n",
    "\n",
    "        print(f\"âœ… Avg RMSE: {avg_rmse:.2f}, Avg RÂ²: {avg_r2:.2f}, Avg MAPE: {avg_mape:.2f}%\")\n",
    "\n",
    "        results.append({\n",
    "            'rmse': avg_rmse,\n",
    "            'r2': avg_r2,\n",
    "            'mape': avg_mape,\n",
    "            'params': params\n",
    "        })\n",
    "\n",
    "    # === Select best hyperparameters ===\n",
    "    best_overall = min(results, key=lambda x: x['rmse'])\n",
    "    print(\"\\nðŸ† Best Hyperparameters Across All Trials:\")\n",
    "    print(f\"RMSE: {best_overall['rmse']:.2f}, RÂ²: {best_overall['r2']:.2f}, MAPE: {best_overall['mape']:.2f}%\")\n",
    "    print(f\"Params: {best_overall['params']}\")\n",
    "\n",
    "    # === Train final model on full 90% training set ===\n",
    "    final_model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', XGBRegressor(random_state=42, **best_overall['params']))\n",
    "    ])\n",
    "    final_model.fit(X_train_full, y_train_full)\n",
    "\n",
    "    # === Evaluate on untouched test set ===\n",
    "    y_pred_test = final_model.predict(X_test)\n",
    "    y_pred_train = final_model.predict(X_train_full)\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    r2_test = r2_score(y_test, y_pred_test) # training set\n",
    "    r2_train = r2_score(y_train_full, y_pred_train)\n",
    "    nonzero_mask_test = y_test != 0\n",
    "    mape_test = np.mean(\n",
    "        np.abs((y_test[nonzero_mask_test] - y_pred_test[nonzero_mask_test]) / y_test[nonzero_mask_test])\n",
    "    ) * 100\n",
    "\n",
    "    print(\"\\nðŸ§ª Final Test Set Performance:\")\n",
    "    print(f\"RMSE: {rmse_test:.2f}\")\n",
    "    print(f\"Train RÂ²: {r2_train:.2f}\")\n",
    "    print(f\"Test RÂ²: {r2_test:.2f}\")\n",
    "    print(f\"MAPE: {mape_test:.2f}%\")\n",
    "\n",
    "    # === SHAP Analysis ===\n",
    "    X_scaled = final_model.named_steps['scaler'].transform(X)\n",
    "    explainer = shap.TreeExplainer(final_model.named_steps['model'])\n",
    "    shap_values = explainer.shap_values(X_scaled)\n",
    "\n",
    "    shap.summary_plot(\n",
    "        shap_values,\n",
    "        features=pd.DataFrame(X_scaled, columns=X.columns),\n",
    "        feature_names=X.columns,\n",
    "        max_display=10\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    #--------NEW CODE---------\n",
    "    # Compute mean absolute SHAP values\n",
    "    mean_abs_shap_values = np.mean(np.abs(shap_values), axis=0)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    shap_df = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'mean_abs_shap': mean_abs_shap_values\n",
    "    })\n",
    "    \n",
    "    # Sort ascending or descending\n",
    "    shap_df = shap_df.sort_values(by='mean_abs_shap', ascending=True)\n",
    "    \n",
    "    # Take bottom 10 or top 10\n",
    "    top_features_df = shap_df.tail(10)\n",
    "    \n",
    "    # Assign a single color (since there is no sign)\n",
    "    bar_color = 'cornflowerblue'\n",
    "    \n",
    "    # === Plot ===\n",
    "    plt.figure(figsize=(8,6))\n",
    "    bars = plt.barh(\n",
    "        y=top_features_df['feature'],\n",
    "        width=top_features_df['mean_abs_shap'],\n",
    "        color=bar_color\n",
    "    )\n",
    "    \n",
    "    plt.axvline(0, color='gray', linewidth=1)\n",
    "    plt.xlim(0, 3)  # no negatives since values are absolute\n",
    "    \n",
    "    # Labels\n",
    "    plt.xlabel(\"Mean Absolute SHAP Value\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.title(\"Top 10 Features by Mean Absolute SHAP\")\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, top_features_df['mean_abs_shap']):\n",
    "        plt.text(\n",
    "            val + 0.02,\n",
    "            bar.get_y() + bar.get_height()/2,\n",
    "            f\"{val:.3f}\",\n",
    "            va='center',\n",
    "            ha='left'\n",
    "        )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Append predictions to dataframe\n",
    "    df['Predicted'] = final_model.predict(X)\n",
    "    df['Differences'] = df['Predicted'] - y\n",
    "    df['FIPS'] = temp\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c656f79d-f3ea-4241-9c5b-3d8b3fdbb1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map(df, field, customcolor, min_value, max_value):\n",
    "    df['State, County'] = df['State']+','+df['County']\n",
    "    dfx = df[['FIPS', field, 'State, County']]\n",
    "\n",
    "    if min_value == max_value:\n",
    "        custom_range = (min(dfx[field]), max(dfx[field]))\n",
    "    else:\n",
    "        custom_range = (min_value, max_value)\n",
    "    \n",
    "    fig = px.choropleth(\n",
    "        dfx,\n",
    "        geojson=counties,\n",
    "        locations='FIPS',\n",
    "        featureidkey=\"properties.id\",\n",
    "        color=field,\n",
    "        color_continuous_scale=customcolor,\n",
    "        range_color = custom_range,\n",
    "        scope='usa',\n",
    "        hover_data={'State, County': True, 'FIPS': True}\n",
    "    )\n",
    "    fig.update_layout(margin = {\"r\":0, \"t\":0, \"l\":0, \"b\":0}) #add 0 margins to output\n",
    "    print(field, \"COVID19 Model\")\n",
    "    fig.show()\n",
    "    \n",
    "    # summary_df = df.drop([\"State\", \"County\", \"State, County\", \"FIPS\"], axis=1)\n",
    "    # print(list(summary_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "169e812a-d768-4d52-9da0-e25e5cbd3ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridgeRegression(dataset):\n",
    "    # === Load and clean data ===\n",
    "    df = pd.read_excel(dataset)\n",
    "    \n",
    "    # Drop aggregate state rows\n",
    "    df = df[df['County'].notna()]\n",
    "    \n",
    "    # Drop identifier columns\n",
    "    df = df.drop(columns=[\"FIPS_x\", \"County\", \"State\"], errors=\"ignore\")\n",
    "    \n",
    "    # Keep only numeric data\n",
    "    df_numeric = df.select_dtypes(include=[np.number])\n",
    "    \n",
    "    # Define X and y\n",
    "    X = df_numeric.drop(columns=[\"% Vaccinated\"], errors=\"ignore\")\n",
    "    y = df_numeric[\"% Vaccinated\"]\n",
    "    \n",
    "    # === Impute missing values in X ===\n",
    "    imputer = IterativeImputer(random_state=42)\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    X_df = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "    \n",
    "    # === Drop rows with missing y values (aligned correctly) ===\n",
    "    y = y.reset_index(drop=True)\n",
    "    valid_mask = y.notna()\n",
    "    X_df = X_df[valid_mask].reset_index(drop=True)\n",
    "    y = y[valid_mask].reset_index(drop=True)\n",
    "    \n",
    "    # === Scale features ===\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_df)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, columns=X_df.columns)\n",
    "    \n",
    "    # === Train-test split ===\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.3, random_state=3141)\n",
    "    \n",
    "    # === Fit Ridge regression ===\n",
    "    ridge = Ridge(alpha=1.0)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_pred = ridge.predict(X_test)\n",
    "    \n",
    "    # === Evaluation metrics ===\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred) * 100\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(\"=== Ridge Regression Results ===\")\n",
    "    print(f\"RÂ²: {r2:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAPE: {mape:.2f} %\")\n",
    "    \n",
    "    # Convert coefficients into a DataFrame\n",
    "    coef_df = pd.DataFrame({\n",
    "        'Feature': X_scaled_df.columns,\n",
    "        'Coefficient': ridge.coef_\n",
    "    })\n",
    "    \n",
    "    # Sort by absolute magnitude of the coefficient\n",
    "    top_5 = coef_df.reindex(coef_df.Coefficient.abs().sort_values(ascending=False).index).head(5)\n",
    "    \n",
    "    print(\"Top 5 most influential predictors in Ridge Regression:\")\n",
    "    print(top_5)\n",
    "    \n",
    "    # === Plot predictions (all test samples) ===\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(y_test.values, label=\"Actual\", color=\"cornflowerblue\")\n",
    "    plt.plot(y_pred, label=\"Predicted\", color=\"red\", linestyle=\":\")\n",
    "    plt.title(\"Ridge Regression: Actual vs Predicted % Vaccinated\")\n",
    "    plt.xlabel(\"Test Sample Index\")\n",
    "    plt.ylabel(\"% Vaccinated\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45a5c545-abd9-43a9-b0a3-13015c238cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lassoRegression(dataset):\n",
    "    # Load data\n",
    "    df = pd.read_excel(dataset)\n",
    "    \n",
    "    # Drop rows without county names (to exclude state aggregates)\n",
    "    df = df[df['County'].notna()].copy()\n",
    "    df = df.drop(columns=[\"FIPS\", \"County\", \"State\"], errors=\"ignore\")\n",
    "    \n",
    "    # Drop any non-numeric columns except target\n",
    "    target_col = \"% Vaccinated\"\n",
    "    df_numeric = df.select_dtypes(include=[np.number])\n",
    "    if target_col not in df_numeric.columns:\n",
    "        df_numeric[target_col] = df[target_col]\n",
    "    \n",
    "    # Drop rows where target is missing\n",
    "    df_numeric = df_numeric[df_numeric[target_col].notna()].reset_index(drop=True)\n",
    "    \n",
    "    # Split features and target\n",
    "    X_df = df_numeric.drop(columns=[target_col])\n",
    "    y = df_numeric[target_col]\n",
    "    \n",
    "    # Impute missing values\n",
    "    imputer = IterativeImputer(random_state=42)\n",
    "    X_imputed = imputer.fit_transform(X_df)\n",
    "    X_imputed_df = pd.DataFrame(X_imputed, columns=X_df.columns)\n",
    "    \n",
    "    # Calculate VIF and drop high-VIF columns iteratively\n",
    "    def drop_high_vif(X, threshold=10.0):\n",
    "        while True:\n",
    "            X_const = sm.add_constant(X)\n",
    "            vif = pd.Series(\n",
    "                [variance_inflation_factor(X_const.values, i) for i in range(1, X_const.shape[1])],\n",
    "                index=X.columns\n",
    "            )\n",
    "            max_vif = vif.max()\n",
    "            if max_vif > threshold:\n",
    "                max_vif_feature = vif.idxmax()\n",
    "                print(f\"Dropping '{max_vif_feature}' due to high VIF ({max_vif:.2f})\")\n",
    "                X = X.drop(columns=[max_vif_feature])\n",
    "            else:\n",
    "                return X, vif\n",
    "    \n",
    "    X_filtered, vif_series = drop_high_vif(pd.DataFrame(X_imputed_df, columns=X_df.columns))\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_filtered)\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Fit Lasso regression\n",
    "    lasso = Lasso(alpha=.05, max_iter=50000, random_state=42)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    y_pred = lasso.predict(X_test)\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    epsilon = 1e-10\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / (y_test + epsilon))) * 100\n",
    "    \n",
    "    print(\"\\n--- Model Performance ---\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")\n",
    "    print(f\"RÂ²: {r2:.3f}\")\n",
    "    \n",
    "    # Top 5 predictors (by absolute coefficient value)\n",
    "    coef_series = pd.Series(lasso.coef_, index=X_filtered.columns)\n",
    "    top5 = coef_series.reindex(coef_series.abs().sort_values(ascending=False).index)[:5]\n",
    "    print(\"\\nTop 5 Predictors (Lasso):\")\n",
    "    print(top5.to_frame(name=\"Coefficient\"))\n",
    "    \n",
    "    # Plot actual vs predicted\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(y_test.values, label='Actual % Vaccinated', color='cornflowerblue')\n",
    "    plt.plot(y_pred, label='Predicted % Vaccinated', color='red', linestyle='--')\n",
    "    plt.title('Lasso Regression: Actual vs Predicted')\n",
    "    plt.xlabel('Sample Index (Test Set)')\n",
    "    plt.ylabel('% Vaccinated')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    '''\n",
    "    # Print VIF table\n",
    "    print(\"\\nFinal VIF Table:\")\n",
    "    vif_table = pd.DataFrame({'Feature': X_filtered.columns, 'VIF': vif_series.values})\n",
    "    print(vif_table)\n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
